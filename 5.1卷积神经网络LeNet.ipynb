{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 二维互相关运算\n",
    "![image.png](image/5.1.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "def corr2d(X, K):\n",
    "    \"\"\"输入数组X和核数组K，输出数组Y\"\"\"\n",
    "    h, w = K.shape\n",
    "    Y = torch.zeros((X.shape[0] - h + 1), (X.shape[1] - w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i, j] = (X[i:i + h, j:j + w] * K).sum()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构造图中的输入数组X和核数组K来验证二维互相关运算的输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[19., 25.],\n",
       "        [37., 43.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[0, 1, 2], [3, 4, 5], [6, 7, 8]])\n",
    "K = torch.tensor([[0, 1], [2, 3]])\n",
    "corr2d(X, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构造一个二维卷积层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2D(nn.Module):\n",
    "    def __init__(self, kernel_size) -> None:\n",
    "        super(Conv2D, self).__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(kernel_size))\n",
    "        self.bias = nn.Parameter(torch.randn(1))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return corr2d(x, self.weight) + self.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "卷积层的一个简单应用是检测图像中物体的边缘，即像素变化的位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.ones(6, 8)\n",
    "X[:, 2:6] = 0\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构造一个1*2的卷积核K，如果横向相邻元素相同，输出为0，否则输出为非0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = torch.tensor([[1, -1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = corr2d(X, K)\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 通过数据学习核数组\n",
    "构造一个卷积层，卷积核将被初始化成随机数组，在接下来的每一次迭代中，利用平方误差来比较Y和卷积层的输出，然后计算梯度来更新卷积核"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------StartTraining-----------\n",
      "Step 5, loss 15.599\n",
      "weight: tensor([[-0.0059,  0.0006]])\n",
      "bias: tensor([0.0033])\n",
      "---------------------------------\n",
      "Step 10, loss 4.344\n",
      "weight: tensor([[ 0.4696, -0.4715]])\n",
      "bias: tensor([0.0010])\n",
      "---------------------------------\n",
      "Step 15, loss 1.210\n",
      "weight: tensor([[ 0.7203, -0.7209]])\n",
      "bias: tensor([0.0003])\n",
      "---------------------------------\n",
      "Step 20, loss 0.337\n",
      "weight: tensor([[ 0.8524, -0.8526]])\n",
      "bias: tensor([0.0001])\n",
      "---------------------------------\n",
      "Step 25, loss 0.094\n",
      "weight: tensor([[ 0.9221, -0.9222]])\n",
      "bias: tensor([3.8585e-05])\n",
      "---------------------------------\n",
      "Step 30, loss 0.026\n",
      "weight: tensor([[ 0.9589, -0.9589]])\n",
      "bias: tensor([1.2874e-05])\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 构造一个核数组形装饰1*2的二维卷积层\n",
    "conv2d = Conv2D(kernel_size=(1, 2))\n",
    "\n",
    "step = 30\n",
    "lr = 0.01\n",
    "print('---------StartTraining-----------')\n",
    "for i in range(step):\n",
    "    Y_hat = conv2d(X)\n",
    "    l = ((Y_hat - Y) ** 2).sum()\n",
    "    l.backward()\n",
    "\n",
    "    # 梯度下降\n",
    "    conv2d.weight.data -= lr * conv2d.weight.grad\n",
    "    conv2d.bias.data -= lr * conv2d.bias.grad\n",
    "\n",
    "    # 梯度清零\n",
    "    conv2d.weight.grad.fill_(0)\n",
    "    conv2d.bias.grad.fill_(0)\n",
    "    \n",
    "    if (i + 1) % 5 == 0:\n",
    "        print('Step %d, loss %.3f' % (i + 1, l.item()))\n",
    "        print('weight:', conv2d.weight.data)\n",
    "        print('bias:', conv2d.bias.data)\n",
    "        print('---------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "事实上，为了得到卷积运算的输出，我们只需要将核数组左右翻转并上下翻转，再与输入数组做互相关运算即可，所以在实践中二者是等效的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "二维卷积层输出的二维数组叫做特征图，影响特征图中某个元素的计算结果的对应的输入区域叫做这个元素的感受野，我们可以通过更深的卷积神经网络让特征图中的单个元素的感受野变得更加广阔，从而捕捉输入上更大尺寸的特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过填充和步幅，我们可以改变输出形状，即便输入和卷积核形状已经确定\n",
    "![image.png](image/5.2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 填充和步幅\n",
    "通常我们会让输入和输出拥有相同的高和宽"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定义一个函数来计算卷积层。它对输入和输出做相应的升维和降维\n",
    "def comp_conv2d(conv2d, X):\n",
    "    # (1, 1)代表批量大小和通道数（“多输入通道和多输出通道”一节将介绍）均为1\n",
    "    X = X.view((1, 1) + X.shape)\n",
    "    Y = conv2d(X)\n",
    "    return Y.view(Y.shape[2:])  # 排除不关心的前两维：批量和通道\n",
    "\n",
    "# 注意这里是两侧分别填充1行或列，所以在两侧一共填充2行或列\n",
    "conv2d = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3, padding=1)\n",
    "\n",
    "X = torch.rand(8, 8)\n",
    "comp_conv2d(conv2d, X).shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 填充\n",
    "当卷积核的高和宽不同时，我们可以设置高和宽上不同的填充数让输出和输入有相同的高和宽"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用高为5、宽为3的卷积核。在高和宽两侧的填充数分别为2和1\n",
    "conv2d = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(5, 3), padding=(2, 1))\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 步幅\n",
    "![image.png](image/5.3.jpg)\n",
    "具体而言，输出尺寸可以用以下公式计算\n",
    "$$output=\\lfloor\\frac{input+2\\times padding-kernel}{stride}\\rfloor+1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多输入通道和多输出通道\n",
    "多输入通道\\\n",
    "当输入图片为彩色的时候，图像在高和宽之外还有RGB三个颜色通道，其可以表示成一个3\\*h\\*w的多维数组\\\n",
    "要实现多个输入通道的互相关运算，只需要对每个通道做互相关运算，然后通过`add_n`函数来进行累加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import d2lzh_pytorch as d2l\n",
    "\n",
    "def corr2d_multi_in(X, K):\n",
    "    # 沿着K和X的第0维（通道维）分别计算再相加\n",
    "    res = d2l.corr2d(X[0, :, :], K[0, :, :])\n",
    "    for i in range(1, X.shape[0]):\n",
    "        res += d2l.corr2d(X[i, :, :], K[i, :, :])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  72.],\n",
       "        [104., 120.]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[[0, 1, 2], [3, 4, 5], [6, 7, 8]],\n",
    "              [[1, 2, 3], [4, 5, 6], [7, 8, 9]]])\n",
    "K = torch.tensor([[[0, 1], [2, 3]], [[1, 2], [3, 4]]])\n",
    "\n",
    "corr2d_multi_in(X, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多输出通道"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in_out(X, K):\n",
    "    #对K的第0维遍历，每次输入X做互相关运算，所有结果用stack函数合并在一起\n",
    "    return torch.stack([corr2d_multi_in(X, k) for k in K])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 2, 2])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将核数组K和K+1，K+2拼在一起构造一个输出通道数为3的卷积核\n",
    "K = torch.stack([K, K + 1, K + 2])\n",
    "K.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 56.,  72.],\n",
       "         [104., 120.]],\n",
       "\n",
       "        [[ 76., 100.],\n",
       "         [148., 172.]],\n",
       "\n",
       "        [[ 96., 128.],\n",
       "         [192., 224.]]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr2d_multi_in_out(X, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 $\\times$ 1卷积层\\\n",
    "这种卷积运算失去了可以识别高和宽维度上相邻元素构成的模式的功能，主要使用在通道维上，输出中的每个元素来自输入中相同位置不同通道间按权重累加的结果，假设我们将通道维当作特征维，将高和宽维度上的元素当作数据样本，那么该卷积层的作用和全连接层等价"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in_out_1x1(X, K):\n",
    "    c_i, h, w = X.shape\n",
    "    c_o = K.shape[0]\n",
    "    X = X.view(c_i, h * w)\n",
    "    K = K.view(c_o, c_i)\n",
    "    Y = torch.mm(K, X)\n",
    "    return Y.view(c_o, h, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "做1 $\\times$ 1卷积时，以上函数和之前实现的`corr2d_multi_in_out`等价"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.rand(3, 3, 3)\n",
    "K = torch.rand(2, 3, 1, 1)\n",
    "\n",
    "Y1 = corr2d_multi_in_out_1x1(X, K)\n",
    "Y2 = corr2d_multi_in_out(X, K)\n",
    "\n",
    "(Y1 - Y2).norm().item() < 1e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在之后的模型里我们将会看到1×1卷积层被当作保持高和宽维度形状不变的全连接层使用。于是，我们可以通过调整网络层之间的通道数来控制模型复杂度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 池化层\n",
    "池化(pooling)层，它的提出是为了缓解卷积层对位置的过度敏感性\\\n",
    "不同于卷积层里计算输入和核的互相关性，池化层直接计算池化窗口内元素的最大值或者平均值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool2d(X, pool_size, mode='max'):\n",
    "    X = X.float()\n",
    "    p_h, p_w = pool_size\n",
    "    Y = torch.zeros(X.shape[0] - p_h + 1, X.shape[1] - p_w + 1)\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            if mode == 'max':\n",
    "                Y[i, j] = X[i: i + p_h, j: j+ p_w].max()\n",
    "            elif mode == 'avg':\n",
    "                Y[i, j] = X[i: i + p_h, j: j+ p_w].mean()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 5.],\n",
       "        [7., 8.]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[0, 1, 2], [3, 4, 5], [6, 7, 8]])\n",
    "pool2d(X, (2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 3.],\n",
       "        [5., 6.]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d(X, (2, 2), 'avg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "和卷积层一样，池化层也可以输入高和宽两侧的填充并调整窗口的移动步幅来改变输出形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.,  1.,  2.,  3.],\n",
       "          [ 4.,  5.,  6.,  7.],\n",
       "          [ 8.,  9., 10., 11.],\n",
       "          [12., 13., 14., 15.]]]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(16, dtype=torch.float).view((1, 1, 4, 4)) # 前两个维度分别是批量和通道\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "默认状态下，`MaxPool2d`实例里的步幅和池化窗口形状相同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[10.]]]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d = nn.MaxPool2d(3)\n",
    "pool2d(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以手动指定步幅和填充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 5.,  7.],\n",
       "          [13., 15.]]]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d = nn.MaxPool2d(3, padding=1, stride=2)\n",
    "pool2d(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "也可以指定非正方形的池化窗口"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.,  3.],\n",
       "          [ 9., 11.],\n",
       "          [13., 15.]]]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d = nn.MaxPool2d((2, 4), padding=(1, 2), stride=(2, 3))\n",
    "pool2d(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在处理多通道的数据时，池化层对每个输入通道分别池化，而不是像卷积层一样将各通道的输入按通道相加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.,  1.,  2.,  3.],\n",
       "          [ 4.,  5.,  6.,  7.],\n",
       "          [ 8.,  9., 10., 11.],\n",
       "          [12., 13., 14., 15.]],\n",
       "\n",
       "         [[ 1.,  2.,  3.,  4.],\n",
       "          [ 5.,  6.,  7.,  8.],\n",
       "          [ 9., 10., 11., 12.],\n",
       "          [13., 14., 15., 16.]]]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.cat((X, X + 1), dim=1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 5.,  7.],\n",
       "          [13., 15.]],\n",
       "\n",
       "         [[ 6.,  8.],\n",
       "          [14., 16.]]]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d = nn.MaxPool2d(3, padding=1, stride=2)\n",
    "pool2d(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在先前用多层感知机对Fashion-MNIST数据集中的图像进行分类的时候，我们将图像逐行展开，得到长度为784的向量，并输入到全联接层中，但是这种方法存在的局限性有\n",
    "1. 在图像中临近的像素在向量中相距可能较远，其构成的模式可能难以被模型识别\n",
    "2. 对于大尺度的输入图像，使用全联接层可能导致模型过大，模型参数会占用过高的存储开销\n",
    "\n",
    "卷积层对这两个问题的解决方式为\n",
    "\n",
    "1. 卷积层保留输入形状，让图像像素在高和宽两个方向上的相关性均有可能被识别\n",
    "2. 通过滑动窗口将同一卷积核与不同位置的输入重复计算，从而避免参数尺寸过大"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LeNet卷积神经网络\n",
    "LeNet的网络结构\n",
    "![image.png](image/5.4.jpg)\n",
    "整体上，LeNet分为卷积层块和全连接层块两个部分\n",
    "\n",
    "卷积层块里的基本单位为卷积层+最大池化层，卷积层用来识别图像里的空间模式，最大池化层用来降低卷积层对位置的敏感性。在卷积层块中，每个卷积层使用5x5的窗口，并在输出上使用sigmoid激活函数，第一个卷积层输出通道数为6，第二个卷积层输出通道数为16（这是由于第二个卷积层比第一个卷积层的输出高和宽要小），卷积层块的两个最大池化层的窗口形状均为2x2，且步幅为2\n",
    "\n",
    "卷积层块的输出形状为（批量大小，通道，高，宽），输入到全连接层块时，全连接层块会将小批量中的每个样本变平，将全连接层的输入变成二维，第一维是小批量中的样本，第二维是每个样本变平后的向量，长度为通道x高x宽，全连接层块包含三个全连接层，输出个数分别为120，84和10，其中10为输出的类别个数\n",
    "\n",
    "下面通过`Sequential`类来实现LeNet模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from torch import optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import d2lzh_pytorch as d2l\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, 5), # in_channels, out_channels, kernel_size\n",
    "            nn.Sigmoid(),\n",
    "            nn.MaxPool2d(2, 2), # kernel_size, stride\n",
    "            nn.Conv2d(6, 16, 5),\n",
    "            nn.Sigmoid(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(16*4*4, 120),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(84, 10)\n",
    "        )\n",
    "    \n",
    "    def forward(self, img):\n",
    "        feature = self.conv(img)\n",
    "        output = self.fc(feature.view(img.shape[0], -1))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): Sigmoid()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (4): Sigmoid()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=120, bias=True)\n",
      "    (1): Sigmoid()\n",
      "    (2): Linear(in_features=120, out_features=84, bias=True)\n",
      "    (3): Sigmoid()\n",
      "    (4): Linear(in_features=84, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = LeNet()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size=batch_size)\n",
    "\n",
    "# 实时可视化训练数据\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为我们要用GPU加速计算，所以需要对`evaluate_accuracy`函数作修改使其支持GPU计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter, net, device=None):\n",
    "    if device is None and isinstance(net, torch.nn.Module):\n",
    "        # 如果没有指定device，就是用net的device\n",
    "        device = list(net.parameters())[0].device\n",
    "    acc_sum, n = 0.0, 0\n",
    "    with torch.no_grad():   # 不记录梯度\n",
    "        for X, y in data_iter:\n",
    "            if isinstance(net, torch.nn.Module):\n",
    "                net.eval() # 评估模式，这会关闭dropout\n",
    "                acc_sum += (net(X.to(device)).argmax(dim=1) == y.to(device)).float().sum().cpu().item()\n",
    "                net.train() # 改回训练模式\n",
    "            else:\n",
    "                if ('is_training' in net.__code__.co_varnames): # 如果有is_training这个参数\n",
    "                    acc_sum += (net(X, is_training=False).argmax(dim=1) == y).float().sum().item()\n",
    "                else:\n",
    "                    acc_sum += (net(X).argmax(dim=1) == y).float().sum().item()\n",
    "            n += y.shape[0]\n",
    "    return acc_sum / n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同样的，训练的函数也需要作修改以适应GPU加速"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs, writer=None):\n",
    "    net = net.to(device)\n",
    "    print('training on', device)\n",
    "    loss = torch.nn.CrossEntropyLoss()\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n, batch_count, start = 0.0, 0.0, 0, 0, time.time()\n",
    "        for X, y in train_iter:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y)\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            train_l_sum += l.cpu().item()\n",
    "            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().cpu().item()\n",
    "            n += y.shape[0]\n",
    "            batch_count += 1\n",
    "        test_acc = evaluate_accuracy(test_iter, net)\n",
    "        if writer is None:\n",
    "            print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec'\n",
    "              % (epoch + 1, train_l_sum / batch_count, train_acc_sum / n, test_acc, time.time() - start))\n",
    "        else:\n",
    "            writer.add_scalar('Train Loss', l.item(), epoch + 1)\n",
    "            writer.add_scalar('Train Accuracy', train_acc_sum / n, epoch + 1)\n",
    "            writer.add_scalar('Test Accuracy', test_acc, epoch + 1)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on mps\n",
      "epoch 1, loss 0.6487, train acc 0.749, test acc 0.747, time 7.1 sec\n",
      "epoch 2, loss 0.6069, train acc 0.763, test acc 0.764, time 7.8 sec\n",
      "epoch 3, loss 0.5742, train acc 0.775, test acc 0.778, time 7.2 sec\n",
      "epoch 4, loss 0.5489, train acc 0.785, test acc 0.782, time 7.1 sec\n",
      "epoch 5, loss 0.5265, train acc 0.795, test acc 0.794, time 6.8 sec\n",
      "epoch 6, loss 0.5074, train acc 0.802, test acc 0.793, time 6.7 sec\n",
      "epoch 7, loss 0.4927, train acc 0.809, test acc 0.802, time 6.7 sec\n",
      "epoch 8, loss 0.4797, train acc 0.813, test acc 0.802, time 7.3 sec\n",
      "epoch 9, loss 0.4659, train acc 0.819, test acc 0.817, time 7.0 sec\n",
      "epoch 10, loss 0.4550, train acc 0.825, test acc 0.817, time 6.7 sec\n",
      "epoch 11, loss 0.4435, train acc 0.831, test acc 0.821, time 6.7 sec\n",
      "epoch 12, loss 0.4308, train acc 0.837, test acc 0.831, time 7.1 sec\n",
      "epoch 13, loss 0.4228, train acc 0.840, test acc 0.835, time 7.2 sec\n",
      "epoch 14, loss 0.4102, train acc 0.846, test acc 0.825, time 7.1 sec\n",
      "epoch 15, loss 0.4042, train acc 0.848, test acc 0.841, time 7.5 sec\n",
      "epoch 16, loss 0.3963, train acc 0.852, test acc 0.845, time 7.4 sec\n",
      "epoch 17, loss 0.3881, train acc 0.855, test acc 0.839, time 8.2 sec\n",
      "epoch 18, loss 0.3782, train acc 0.859, test acc 0.847, time 7.6 sec\n",
      "epoch 19, loss 0.3743, train acc 0.861, test acc 0.853, time 7.0 sec\n",
      "epoch 20, loss 0.3660, train acc 0.864, test acc 0.850, time 7.9 sec\n",
      "epoch 21, loss 0.3605, train acc 0.867, test acc 0.851, time 7.9 sec\n",
      "epoch 22, loss 0.3581, train acc 0.867, test acc 0.858, time 7.7 sec\n",
      "epoch 23, loss 0.3514, train acc 0.871, test acc 0.857, time 7.7 sec\n",
      "epoch 24, loss 0.3466, train acc 0.872, test acc 0.857, time 8.0 sec\n",
      "epoch 25, loss 0.3420, train acc 0.874, test acc 0.862, time 8.2 sec\n",
      "epoch 26, loss 0.3360, train acc 0.876, test acc 0.863, time 8.3 sec\n",
      "epoch 27, loss 0.3369, train acc 0.876, test acc 0.866, time 7.6 sec\n",
      "epoch 28, loss 0.3299, train acc 0.878, test acc 0.862, time 7.3 sec\n",
      "epoch 29, loss 0.3273, train acc 0.878, test acc 0.868, time 7.7 sec\n",
      "epoch 30, loss 0.3255, train acc 0.880, test acc 0.868, time 8.2 sec\n",
      "epoch 31, loss 0.3205, train acc 0.882, test acc 0.865, time 7.2 sec\n",
      "epoch 32, loss 0.3188, train acc 0.881, test acc 0.868, time 6.6 sec\n",
      "epoch 33, loss 0.3153, train acc 0.884, test acc 0.872, time 6.6 sec\n",
      "epoch 34, loss 0.3171, train acc 0.882, test acc 0.872, time 6.7 sec\n",
      "epoch 35, loss 0.3096, train acc 0.886, test acc 0.876, time 6.7 sec\n",
      "epoch 36, loss 0.3089, train acc 0.886, test acc 0.877, time 6.6 sec\n",
      "epoch 37, loss 0.3055, train acc 0.887, test acc 0.875, time 6.6 sec\n",
      "epoch 38, loss 0.3045, train acc 0.887, test acc 0.869, time 6.6 sec\n",
      "epoch 39, loss 0.3039, train acc 0.888, test acc 0.876, time 6.6 sec\n",
      "epoch 40, loss 0.3004, train acc 0.888, test acc 0.872, time 6.6 sec\n",
      "epoch 41, loss 0.2979, train acc 0.889, test acc 0.874, time 6.6 sec\n",
      "epoch 42, loss 0.2946, train acc 0.891, test acc 0.876, time 6.6 sec\n",
      "epoch 43, loss 0.2935, train acc 0.892, test acc 0.880, time 6.7 sec\n",
      "epoch 44, loss 0.2927, train acc 0.891, test acc 0.879, time 7.1 sec\n",
      "epoch 45, loss 0.2903, train acc 0.893, test acc 0.878, time 7.1 sec\n",
      "epoch 46, loss 0.2884, train acc 0.892, test acc 0.878, time 7.4 sec\n",
      "epoch 47, loss 0.2873, train acc 0.893, test acc 0.881, time 7.2 sec\n",
      "epoch 48, loss 0.2855, train acc 0.893, test acc 0.881, time 6.6 sec\n",
      "epoch 49, loss 0.2826, train acc 0.894, test acc 0.883, time 6.6 sec\n",
      "epoch 50, loss 0.2813, train acc 0.894, test acc 0.880, time 6.7 sec\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.001, 50\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv.0.weight torch.Size([6, 1, 5, 5])\n",
      "conv.0.bias torch.Size([6])\n",
      "conv.3.weight torch.Size([16, 6, 5, 5])\n",
      "conv.3.bias torch.Size([16])\n",
      "fc.0.weight torch.Size([120, 256])\n",
      "fc.0.bias torch.Size([120])\n",
      "fc.2.weight torch.Size([84, 120])\n",
      "fc.2.bias torch.Size([84])\n",
      "fc.4.weight torch.Size([10, 84])\n",
      "fc.4.bias torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for name, param in net.named_parameters():\n",
    "    print(name, param.size())\n",
    "\n",
    "torch.save(net.state_dict(), 'test_data/MyFirstLeNet.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
